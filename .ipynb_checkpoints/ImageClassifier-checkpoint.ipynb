{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af30511-d59a-43be-b646-224a29d35446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa93de2b-46d3-4025-82c9-6f4da1b98213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit gpu usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4d4dbe8-15c0-46e6-9db0-62b0ceb4c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for computer vision\n",
    "import cv2\n",
    "#used for checking extensions of images\n",
    "import imghdr\n",
    "# used for viewing images\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0785be59-a9c1-401e-b2fd-29f519eeed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "31425d1b-c590-4f7b-a0ae-78e9992a12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowed extensions\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6bbaa99-143d-4715-ae7c-da237ef6f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view image and convert from BGR to RGB\n",
    "# creates numpy array for the image\n",
    "# img = cv2.imread(os.path.join('data', 'happy', 'smile.woman_.jpg'))\n",
    "# img.shape\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4afec0cc-ec02-4817-b76b-a2dae7ba31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access both directories for happy and sad\n",
    "for image_class in os.listdir(data_dir):\n",
    "    # access each image in the respective directories\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        # get the image path \n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            #img = cv2.imread(image_path)\n",
    "            # get extension of image\n",
    "            tip = imghdr.what(image_path)\n",
    "            # if the extension is not in the list of valid extension then remove it\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.formate(image_path))\n",
    "                # remove the image path\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image {}\".format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d4cb9703-b04e-4905-a1f0-7833c98212a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# loads images from directory \n",
    "# each sub directory is a class label\n",
    "data = tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4729dece-246d-4be7-868d-1e9ce1836040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this converts the data from tensors to numpy arrays\n",
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8371ba3-102f-4693-a206-0a1bf43a064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images represented as numpy arrays\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2f526-ab03-4793-95dd-acfaf319d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 equals sad people\n",
    "# 0 equals happy people\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1c45b-57b5-41e8-8952-bed4aee2bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images to produce\n",
    "number_of_images = 6\n",
    "# create a set of subplots 'ax' and a figure 'fig'\n",
    "fig, ax = plt.subplots(ncols=number_of_images, figsize=(20,20))\n",
    "# take only the first 'number_of_images' from batch\n",
    "# get the index and the value using enumerate\n",
    "for idx, img in enumerate(batch[0][:number_of_images]):\n",
    "    # display the images\n",
    "    ax[idx].imshow(img)\n",
    "    #display the labels\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da3f8510-6136-47af-b3bf-c33c5e18cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = data.map(lambda x, y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa74b30a-70db-47d9-b4e3-d523d416e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = scaled_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "965a485d-3aa9-4e39-b7d3-eb75a1939b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028fd20-7e9e-40a1-a1ab-8b1accb6bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images to produce\n",
    "number_of_images = 6\n",
    "# create a set of subplots 'ax' and a figure 'fig'\n",
    "fig, ax = plt.subplots(ncols=number_of_images, figsize=(20,20))\n",
    "# take only the first 'number_of_images' from batch\n",
    "# get the index and the value using enumerate\n",
    "for idx, img in enumerate(scaled_batch[0][:number_of_images]):\n",
    "    # display the images\n",
    "    ax[idx].imshow(img)\n",
    "    #display the labels\n",
    "    ax[idx].title.set_text(scaled_batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "511e0cfd-38eb-4f15-9dd4-d9ea849d2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "val_size = int(len(data) * .2)\n",
    "test_size = int(len(data) * .1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "095c2db6-d84d-4c22-9614-68af1767debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a5b9199d-e5b1-4fd5-9add-d4c02ef0b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1bbfb662-1d1f-49db-a714-96c0f352b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "75247055-3c1f-4bef-bff7-01ab57b48e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "373cec9a-1620-45c3-8ec0-3959b331ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "91ca10af-d07d-4c07-a022-29cd1789c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3696625 (14.10 MB)\n",
      "Trainable params: 3696625 (14.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fb85199b-b0b3-452b-aa79-6721457869a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ed60d-422c-4af6-97e6-7b8788645156",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4982829-b720-4f45-8d0e-5a2964461a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='blue', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='yellow', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1938d-3df9-4391-a9ac-fd55f5ece922",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='blue', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='yellow', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24e69a1c-43c7-404c-8b35-2258b3a516e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "94fe1575-100c-4ba1-a4d4-95d6f80ab0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Precision()\n",
    "recall = Recall()\n",
    "accuracy = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c3d10fd-5733-4f91-ab23-6b44364a8e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    precision.update_state(y, yhat)\n",
    "    recall.update_state(y, yhat)\n",
    "    accuracy.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9c44f086-6051-4204-82bc-4c5c4ee5f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:1.0\n",
      "Recall:1.0\n",
      "Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision:{precision.result().numpy()}')\n",
    "print(f'Recall:{recall.result().numpy()}')\n",
    "print(f'Accuracy:{accuracy.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb39b9-96a4-4e48-b68e-e6ffae7b70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('testimages/jakesad.png')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0faf98e-6f14-489f-a5ef-3b6f56cd1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "822a66a4-f241-4bc8-9583-07b3cafaa149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d74db768-79a1-4d0a-ad92-d48218b4c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.520332]]\n",
      "Predicted Sad\n"
     ]
    }
   ],
   "source": [
    "print(yhat)\n",
    "if(yhat > .5):\n",
    "    print(\"Predicted Sad\")\n",
    "else:\n",
    "    print(\"Predicted Happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c3d2ed6e-e957-4807-80db-0bdbd24647af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9793dd21-8eaf-4213-9e63-9b9f58aba0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models', 'happysadmodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "91ac2b93-3ca5-4a26-be66-fc0f7cc2e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models', 'happysadmodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b916dddf-3363-4d1d-a52c-8d612424f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.520332]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb82348-3522-44ab-9339-a7c8ab68ff17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
